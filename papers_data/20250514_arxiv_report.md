以下是根据您要求整理的每篇论文的内容，包括标题、摘要和论文亮点：

1. **标题**：ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning Corpus  
   **摘要**：ARC-NCA引入了一种基于标准神经细胞自动机（NCA）及增强记忆的NCA（EngramNCA）的发展性方法来解决ARC-AGI基准测试。该方法利用了NCA模拟复杂动态和出现模式的能力，旨在模仿生物系统中的发展过程。通过将发展原则整合到计算模型中，ARC-NCA展示了如何促进适应性推理和抽象。实验结果表明，ARC-NCA的效果可以与ChatGPT 4.5相媲美甚至超越，且成本更低。  
   **论文亮点**：提出了一种新的发展性解决方案，使用NCA和EngramNCA来处理ARC-AGI挑战；实验结果显示其性能优于或等于现有模型，但资源消耗更少。

2. **标题**：Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology  
   **摘要**：本文介绍了CityAVOS数据集和PRPSearcher方法，用于城市环境中无人机自主视觉目标搜索任务。CityAVOS包含了2420个任务，覆盖六个不同难度级别的对象类别。PRPSearcher则结合了多模态大语言模型，构建了三个专门的地图以增强空间感知、推理和探索效率。  
   **论文亮点**：首次提出了针对城市环境的无人机视觉搜索基准CityAVOS；PRPSearcher方法在成功率和搜索效率方面显著优于现有基线。

3. **标题**：Securing RAG: A Risk Assessment and Mitigation Framework  
   **摘要**：随着检索增强生成（RAG）技术成为自然语言处理应用的标准，本文探讨了RAG管道中存在的安全风险，并提出了一套框架来指导实现稳健、合规的安全RAG系统。该框架结合了特定于RAG的安全考虑因素以及现有的通用安全指南。  
   **论文亮点**：全面分析了RAG系统的潜在漏洞，并提供了详细的缓解措施；开发了一个结构化的框架，帮助实施者确保系统的安全性。

4. **标题**：Memorization-Compression Cycles Improve Generalization  
   **摘要**：作者证明了通过压缩内部表示可以改善泛化能力，并引入了信息瓶颈语言建模（IBLM）目标。实验证明，在预训练期间存在记忆-压缩循环现象，这有助于提高模型的表现。此外，提出的GAPT算法可以在不同阶段之间切换，从而减少干扰并改善分离度。  
   **论文亮点**：发现了预训练过程中存在的记忆-压缩循环；提出了GAPT算法，能够自适应地调整训练过程，提高泛化能力和分离度。

5. **标题**：LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs  
   **摘要**：本研究探讨了使用大型语言模型（LLMs）进行医疗实体识别的方法，特别是通过集成提示策略提高了可靠性。实验表明，采用GPT-4o和多种提示工程技术相结合的方式，在F1分数和召回率上都取得了最佳成绩。  
   **论文亮点**：使用LLMs和集成提示策略实现了高精度的医疗实体识别；GPT-4o与提示集成相比其他模型表现出色。

6. **标题**：WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation  
   **摘要**：WixQA是一个面向企业级检索增强生成的新基准，它基于实际客户支持互动创建了三个不同的问答数据集，并附带了相应的知识库快照。这些数据集为评估RAG系统的检索和生成组件提供了全面的支持。  
   **论文亮点**：提供了三个真实场景下的问答数据集及其对应的知识库快照；形成了一个完整的基准，可用于评估企业级RAG系统的性能。

7. **标题**：TRAIL: Trace Reasoning and Agentic Issue Localization  
   **摘要**：本文关注于代理工作流产生的复杂跟踪记录的评估问题，提出了TRAIL数据集，其中包括148个人工标注的跟踪记录。通过对这些记录的研究，发现现代长上下文LLMs在调试方面表现不佳。  
   **论文亮点**：建立了TRAIL数据集，包含大量人工标注的代理工作流跟踪记录；揭示了当前LLMs在处理复杂跟踪记录时的局限性。

8. **标题**：Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models  
   **摘要**：为了解决文本到图像生成模型中有效提示难以创建的问题，本文提出了无需梯度的硬提示反转方法VGD。该方法利用LLMs生成可读性强且语义一致的提示，并通过CLIP评分确保与用户指定视觉概念的一致性。  
   **论文亮点**：提出了VGD方法，不依赖梯度即可生成高质量的提示；相比传统方法，VGD生成的提示更具解释性和灵活性。

9. **标题**：Resource-Efficient Language Models: Quantization for Fast and Accessible Inference  
   **摘要**：本文综述了后训练量化（PTQ）技术，旨在优化大型语言模型的推理效率。讨论了各种量化方案及其权衡关系，旨在提供关于PTQ理论与应用之间的平衡概述。  
   **论文亮点**：详细介绍了PTQ技术及其在优化LLM推理效率方面的应用；提供了关于量化方案选择的实用建议。

10. **标题**：Small but Significant: On the Promise of Small Language Models for Accessible AIED  
    **摘要**：尽管大型语言模型（LLMs）在教育领域展现出巨大潜力，但本文强调小型语言模型（SLMs）同样具有重要意义，尤其是在资源受限的情况下。研究表明，SLMs可以在不需要复杂提示策略的情况下取得良好效果。  
    **论文亮点**：呼吁更多关注SLMs的应用，特别是在资源有限的环境中；展示了SLMs在关键教育挑战上的有效性。

11. **标题**：TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching  
    **摘要**：本文介绍了一个名为TrialMatchAI的人工智能驱动临床试验推荐系统，旨在自动化患者与试验之间的匹配过程。该系统利用开源LLMs和检索增强生成框架，确保透明度和轻量级部署。  
    **论文亮点**：开发了一个高效的临床试验推荐系统，能够在实际环境中快速准确地找到合适的试验；支持模块化设计和隐私保护功能。

12. **标题**：Achieving Scalable Robot Autonomy via Neurosymbolic Planning Using Lightweight Local LLM  
    **摘要**：本文提出了Gideon框架，通过使用较小规模的本地LLMs来实现可扩展的机器人自主性。Gideon通过生成大规模的真实域问题计划元组数据集，并适应本地LLMs进行神经符号规划，从而实现设备端执行和跨域支持。  
    **论文亮点**：通过Gideon框架实现了轻量级本地LLMs的高效应用；展示了在单域和多域场景下良好的计划有效性。

13. **标题**：Strategy-Augmented Planning for Large Language Models via Opponent Exploitation  
    **摘要**：本文提出了一种两阶段的策略增强规划（SAP）框架，以提升LLMs在对抗领域中的对手利用能力。SAP框架在线下阶段构建策略空间并收集数据，在线上阶段动态识别对手策略并作出响应。  
    **论文亮点**：引入了SAP框架，显著增强了LLMs在对抗环境中的对手利用能力；实验结果表明SAP在多个环境下均表现出色。

14. **标题**：Hakim: Farsi Text Embedding Model  
    **摘要**：本文介绍了Hakim，一种新型的波斯语文本嵌入模型，在FaMTEB基准测试中取得了8.5%的性能提升。同时，还发布了三个新数据集，用于监督和非监督学习场景。  
    **论文亮点**：提出了首个专门针对波斯语的高性能文本嵌入模型；引入了三个新数据集以支持波斯语NLP任务。

15. **标题**：Adaptive Diffusion Policy Optimization for Robotic Manipulation  
    **摘要**：本文提出了一种基于Adam的扩散策略优化（ADPO）算法，用于快速稳定地微调扩散模型在机器人控制任务中的表现。实验表明，ADPO在多个标准机器人任务上优于其他扩散模型方法。  
    **论文亮点**：提出了ADPO算法，显著提高了扩散模型在机器人控制任务中的表现；提供了超参数敏感性的系统分析。

16. **标题**：Modeling Unseen Environments with Language-Guided Composable Causal Components in Reinforcement Learning  
    **摘要**：本文提出了World Modeling with Compositional Causal Components（WM3C），这是一个新的框架，通过组合因果组件来增强强化学习中的泛化能力。WM3C利用语言作为组合模态，将潜在空间分解为有意义的组件，并提供理论保证。  
    **论文亮点**：提出了WM3C框架，通过组合因果组件实现了对未见环境的有效适应；利用语言引导的分解方法提高了模型的泛化能力。

17. **标题**：STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives  
    **摘要**：本文介绍了StoryAnchors框架，用于生成具有强时间一致性的多场景故事框架。该框架通过双向故事生成器整合过去和未来上下文，确保叙述连贯性和场景多样性。  
    **论文亮点**：提出了StoryAnchors框架，能够生成连贯且多样化的多场景故事框架；实验结果表明其在一致性、连贯性和多样性方面均优于现有模型。

18. **标题**：A Practical Introduction to Deep Reinforcement Learning  
    **摘要**：本文是一篇关于深度强化学习（DRL）的教程，重点介绍了广泛使用的PPO算法。文章通过直观解释、示例和实践技巧，帮助读者快速掌握从基础概念到高级算法的实现。  
    **论文亮点**：提供了一篇易于理解的DRL入门教程；特别强调了PPO算法的应用。

19. **标题**：Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning  
    **摘要**：本文提出了一种自动课程学习框架，用于生成具有自适应复杂度的驾驶场景。该框架通过“教师”模块动态生成和变异场景，从而提高了训练效率和泛化能力。  
    **论文亮点**：提出了自动课程学习框架，动态生成适应性的驾驶场景；实验结果表明该方法在低密度和高密度交通环境中均提高了成功率。

20. **标题**：Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration  
    **摘要**：本文提出了自适应上下文压缩（ACC）技术，用于改进缓存增强生成（CAG）。ACC通过动态压缩和管理上下文输入，提高了CAG的可扩展性和多跳推理性能。  
    **论文亮点**：提出了ACC技术，解决了CAG在处理大规模动态知识库时的挑战；实验表明ACC在多个数据集上表现优异。

1. **标题**: VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large Video Language Models  
   **摘要**: 该研究介绍了VCRBench，一个用于评估大型视频语言模型（LVLMs）在基于视频的长期因果推理能力的新基准。VCRBench使用简单的日常活动程序视频，通过故意打乱步骤并捕捉关键因果事件来测试LVLMs是否能够识别、推理和正确排序实现特定目标所需的事件。实验结果表明，LVLMs在处理长期因果依赖方面存在困难，而提出的Recognition-Reasoning Decomposition（RRD）方法显著提高了模型在这类任务上的准确性。  
   **论文亮点**: 
   - 提出了VCRBench，填补了视频因果推理基准的空白。
   - 通过Recognition-Reasoning Decomposition（RRD）方法将视频因果推理分解为两个子任务，显著提升了模型性能。
   - 实验结果显示LVLMs主要依赖于语言知识来完成复杂的因果推理任务。

2. **标题**: An integrated language-vision foundation model for conversational diagnostics and triaging in primary eye care  
   **摘要**: 本文介绍了一种名为Meta-EyeFM的多功能基础模型，它结合了大型语言模型（LLM）与视觉基础模型（VFMs），用于眼部疾病评估。Meta-EyeFM利用路由机制实现基于文本查询的准确任务特定分析，并通过低秩适应技术对VFMs进行了微调，以检测眼部和全身疾病，区分疾病严重程度，并识别常见的眼部特征。实验结果表明，Meta-EyeFM在多种眼病检测中的表现优于现有模型，并且接近眼科医生的水平。  
   **论文亮点**: 
   - 提出的Meta-EyeFM系统在眼病检测中表现出色，达到了或超过了现有模型的性能。
   - 利用低秩适应技术微调VFMs，显著提高了疾病检测和严重程度区分的准确性。
   - 提供了一个用户友好的界面，增强了系统的可用性和诊断性能。

3. **标题**: MoKD: Multi-Task Optimization for Knowledge Distillation  
   **摘要**: 本文提出了一种称为MoKD的方法，用于解决知识蒸馏（KD）中的梯度冲突和梯度主导问题。MoKD通过多任务优化框架重新定义KD，使学生模型能够在学习教师模型的知识时保持任务目标的一致性。此外，MoKD引入了一个子空间学习框架，以提高特征表示之间的知识传递效率。实验结果表明，MoKD在图像分类和目标检测任务上均取得了最先进的性能。  
   **论文亮点**: 
   - 提出了MoKD，解决了知识蒸馏中的梯度冲突和梯度主导问题。
   - 引入了子空间学习框架，提高了特征表示之间的知识传递效率。
   - 在多个数据集上的实验验证了MoKD的有效性，达到了最先进的性能。

4. **标题**: Preference Optimization for Combinatorial Optimization Problems  
   **摘要**: 本文提出了一种称为Preference Optimization的新方法，旨在通过统计比较建模将定量奖励信号转换为定性偏好信号，从而解决组合优化问题中的奖励信号衰减和探索效率低下问题。该方法通过重新参数化奖励函数并结合局部搜索技术，提高了策略的学习效率和解决方案的质量。实验结果表明，该方法在多个基准测试中显著优于现有的强化学习算法。  
   **论文亮点**: 
   - 提出了Preference Optimization方法，通过统计比较建模将定量奖励信号转换为定性偏好信号。
   - 结合局部搜索技术，帮助策略逃离局部最优，提高了学习效率和解决方案质量。
   - 在多个基准测试中取得了显著优于现有强化学习算法的结果。

5. **标题**: Modular Federated Learning: A Meta-Framework Perspective  
   **摘要**: 本文从模块化组件的角度对联邦学习（FL）进行了系统化的综述，提出了一个新的元框架视角，将FL视为由通信、优化、安全和隐私等核心方面组成的模块化系统。文章还提出了一个新的分类法，区分了聚合和对齐的概念，并探讨了现有的FL框架及其实际应用。  
   **论文亮点**: 
   - 提出了一个新的元框架视角，将FL视为由多个模块化组件组成的系统。
   - 区分了聚合和对齐的概念，提出了新的分类法。
   - 对现有的FL框架进行了详细探讨，并提供了实际应用的指导。

6. **标题**: Credit Assignment and Efficient Exploration based on Influence Scope in Multi-agent Reinforcement Learning  
   **摘要**: 本文提出了一种基于影响范围（ISA）的新方法，用于解决多智能体强化学习（MARL）中的信用分配和有效探索问题。ISA通过计算各智能体对状态维度/属性的影响来确定信用分配，并限制每个智能体的探索空间。实验结果表明，该方法在多个稀疏奖励场景中显著优于现有方法。  
   **论文亮点**: 
   - 提出了基于影响范围（ISA）的新方法，解决了MARL中的信用分配和有效探索问题。
   - 通过计算智能体对状态维度/属性的影响来确定信用分配，提高了学习效率。
   - 在多个稀疏奖励场景中显著优于现有方法。

7. **标题**: Continuous World Coverage Path Planning for Fixed-Wing UAVs using Deep Reinforcement Learning  
   **摘要**: 本文提出了一种基于深度强化学习的方法，用于固定翼无人机（UAV）在连续环境中的覆盖路径规划（CPP）。该方法通过自适应课程学习训练强化学习代理，以最小化能耗并确保完全覆盖。实验结果表明，该方法在学习能量高效的覆盖策略方面具有显著效果。  
   **论文亮点**: 
   - 提出了基于深度强化学习的固定翼UAV覆盖路径规划方法，适用于连续环境。
   - 使用自适应课程学习训练强化学习代理，提高了学习效率。
   - 在多个场景中验证了该方法的有效性，展示了其在能量高效覆盖方面的优势。

8. **标题**: NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance  
   **摘要**: 本文提出了一种称为NavDP的导航扩散策略，用于机器人在动态开放世界环境中的导航学习。NavDP通过结合扩散轨迹生成和基于局部观察的批评函数选择轨迹，实现了从模拟到真实世界的零样本迁移。实验结果表明，NavDP在多种机器人平台和环境中表现出色。  
   **论文亮点**: 
   - 提出了NavDP，一种用于机器人导航学习的端到端框架，实现了从模拟到真实世界的零样本迁移。
   - 结合扩散轨迹生成和基于局部观察的批评函数选择轨迹，提高了导航性能。
   - 在多个机器人平台上验证了其优越的泛化能力和性能。

9. **标题**: End-to-End Multi-Task Policy Learning from NMPC for Quadruped Locomotion  
   **摘要**: 本文提出了一种多任务学习（MTL）框架，用于从非线性模型预测控制（NMPC）专家演示中学习四足机器人的多任务运动策略。该框架通过单个神经网络直接从原始传感器输入预测动作，简化了实时部署的控制管道。实验结果表明，该方法在四足机器人Go1上表现出色，能够平滑切换步态并简化控制流程。  
   **论文亮点**: 
   - 提出了一个多任务学习框架，从NMPC专家演示中学习四足机器人的多任务运动策略。
   - 通过单个神经网络直接从原始传感器输入预测动作，简化了控制管道。
   - 在四足机器人Go1上进行了广泛实验，验证了其高效性和适应性。

10. **标题**: ORACLE-Grasp: Zero-Shot Task-Oriented Robotic Grasping using Large Multimodal Models  
    **摘要**: 本文提出了一种称为ORACLE-Grasp的零样本框架，用于自主机器人抓取未知物体。该框架利用大型多模态模型（LMMs）作为语义预言家，指导抓取选择，无需额外训练或人工输入。实验结果表明，该方法在抓取位置和方向误差方面接近人类标注的地面真值，并在实际拾取任务中取得了高成功率。  
    **论文亮点**: 
    - 提出了ORACLE-Grasp，一种零样本框架，利用LMMs作为语义预言家指导抓取选择。
    - 通过离散化图像空间和推理候选区域，提高了抓取选择的精度。
    - 在实际拾取任务中取得了高成功率，展示了其在自主抓取方面的潜力。

11. **标题**: MA-ROESL: Motion-aware Rapid Reward Optimization for Efficient Robot Skill Learning from Single Videos  
    **摘要**: 本文提出了一种称为MA-ROESL的方法，用于从单个视频中快速优化奖励以提高机器人技能学习的效率。MA-ROESL通过运动感知帧选择方法增强VLM生成的奖励函数质量，并采用混合三阶段训练管道提高训练效率。实验结果表明，MA-ROESL显著提高了训练效率并在模拟和现实环境中忠实再现了运动技能。  
    **论文亮点**: 
    - 提出了MA-ROESL，通过运动感知帧选择方法增强VLM生成的奖励函数质量。
    - 采用混合三阶段训练管道提高训练效率，显著减少了计算开销。
    - 在模拟和现实环境中验证了其高效性和技能再现能力。

12. **标题**: CLTP: Contrastive Language-Tactile Pre-training for 3D Contact Geometry Understanding  
    **摘要**: 本文提出了一种称为CLTP的对比语言触觉预训练框架，用于理解和处理三维接触几何。CLTP通过对齐触觉3D点云与自然语言描述，使机器人能够理解复杂的接触状态。实验结果表明，CLTP在零样本3D分类、接触状态分类和触觉3D大语言模型交互等下游任务中表现出色。  
    **论文亮点**: 
    - 提出了CLTP，首次将触觉和语言表示从接触状态角度对齐，用于复杂接触状态的理解。
    - 收集了一个包含50,000多个触觉3D点云-语言对的新数据集，涵盖了多维接触状态。
    - 在多个下游任务中验证了其优越性能，展示了其在触觉-语言-动作模型学习中的潜力。以下是根据您的要求整理的每篇论文的内容，包括标题、摘要和论文亮点：

1. **标题**：Evaluating LLM Metrics Through Real-World Capabilities  
   **摘要**：本文强调了评估生成式AI性能时应注重实际使用情况而非抽象智能的重要性。通过分析大规模调查数据和使用日志，确定了六大核心能力来代表人们常用的大规模语言模型（LLMs）功能：总结、技术协助、工作审查、数据结构化、生成和信息检索。研究发现Google Gemini在这些实用指标上优于其他模型。  
   **论文亮点**：提出了一种基于实际任务的评估框架，揭示了现有基准测试中存在的覆盖范围不足、效率测量和解释性问题，并通过人类中心标准识别了当前基准与实际使用之间的差距。

2. **标题**：Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles  
   **摘要**：文章探讨了如何利用多智能体强化学习（MARL）控制自主车辆（AV）在复杂海洋环境中执行水下追踪任务。提出了迭代蒸馏方法，将高保真度模拟转换为简化的GPU加速环境，实现了高达30,000倍的速度提升。此外，还引入了基于Transformer架构的多智能体策略学习，提高了样本效率。  
   **论文亮点**：解决了大规模MARL训练中遇到的计算挑战，提供了一个可扩展的框架用于真实世界中的自主车队控制，特别是在多目标追踪方面表现优异。

3. **标题**：Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations  
   **摘要**：介绍了Aitomia平台，该平台结合了大型语言模型（LLMs）、基于规则的代理以及检索增强生成系统（RAG），帮助专家和非专业人士进行原子级和量子化学模拟。它能够设置运行模拟实验、监控计算状态、分析结果并以文本或图形形式呈现给用户。  
   **论文亮点**：降低了执行原子级模拟的技术门槛，促进了相关领域的研究与发展；集成了MLatom生态系统，增强了计算化学中的AI应用。

4. **标题**：DSADF: Thinking Fast and Slow for Decision Making  
   **摘要**：受Kahneman快思考（System 1）和慢思考（System 2）理论启发，提出了一种双系统自适应决策框架（DSADF），整合了快速直观决策模块（由RL代理组成）和深度分析推理模块（由视觉语言模型驱动）。  
   **论文亮点**：实现了两种不同类型的决策系统的有效结合，提高了在复杂环境下的灵活决策能力；展示了在视频游戏环境中显著改善了对已知和未知任务的决策表现。

5. **标题**：Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL  
   **摘要**：针对离线安全强化学习（OSRL）中存在的短期安全性问题，提出了可行性感知悲观估计（FASP）框架。该框架采用Hamilton-Jacobi可达性分析生成可靠的标签作为监督信号，并使用条件变分自动编码器（CVAE）和安全性分类器进行训练，确保长期安全性。  
   **论文亮点**：不仅提高了采样效率，而且提供了严格的长期安全保障；通过悲观估计方法减少了由于未见过的数据导致的外推错误，主动避免高风险行为。

6. **标题**：Decoding Neighborhood Environments with Large Language Models  
   **摘要**：探索了大型语言模型（LLMs）如ChatGPT和Gemini作为工具解码邻里环境（例如人行道和电线杆）的可能性。研究开发了一个基于YOLOv11的鲁棒模型，用于检测六个环境指标，准确率达到99.13%。同时评估了几种LLMs在识别这些指标方面的可行性和局限性。  
   **论文亮点**：无需任何训练努力即可实现超过88%的准确性；证明了LLMs可以作为一种有效的工具来大规模地解码邻里环境特征。

7. **标题**：Lost in Transmission: When and Why LLMs Fail to Reason Globally  
   **摘要**：探讨了大型语言模型（LLMs）在全球范围内处理复杂推理任务时失败的原因，归因于内部通信带宽限制。引入了有界注意前缀预言机（BAPO）模型，用于模拟注意力头之间的带宽约束。研究表明，某些需要高带宽的问题对于BAPO来说是困难的。  
   **论文亮点**：提供了关于LLM失败原因的原则性解释，并建议了改进架构和推理方法的方向；证明了分解任务可以将任何BAPO难问题转化为易问题。

8. **标题**：HealthBench: Evaluating Large Language Models Towards Improved Human Health  
   **摘要**：介绍了HealthBench，一个开源基准，用于衡量大型语言模型在医疗保健领域的性能和安全性。包含5,000次多轮对话，涉及多个健康上下文和行为维度。结果显示，较小的模型在成本效益方面表现出色。  
   **论文亮点**：提供了一个全面且现实的评估平台，有助于推动有利于人类健康的模型开发；特别关注模型行为的重要维度，确保其在医疗场景中的适用性和可靠性。

9. **标题**：Aya Vision: Advancing the Frontier of Multilingual Multimodality  
   **摘要**：为了解决构建多模态语言模型面临的挑战，提出了合成注释框架和跨模态模型融合技术，使得Aya Vision模型能够在多种语言中产生自然的人类偏好响应。Aya-Vision-8B和Aya-Vision-32B分别超越了其他强大的多模态模型。  
   **论文亮点**：极大地推进了多语言多模态领域的前沿，尤其在保持文本能力的同时增强了多模态生成性能；减少了计算需求的同时实现了极高的性能水平。

10. **标题**：AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models  
    **摘要**：提出了一种半正式推理框架AC-Reason，用于解决实际因果关系中的归属和责任分配问题。该框架不显式构造因果图，而是操作底层因果结构中的变量，支持原则性的推理过程。  
    **论文亮点**：引入了新的基准AC-Bench，专注于实际因果关系，测试结果表明GPT-4+AC-Reason在两个基准上的表现最佳；通过细粒度分析揭示了只有少数几个模型展示了忠实的推理逻辑。

11. **标题**：Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies  
    **摘要**：研究了大型语言模型（LLMs）是否可以在不同的标记顺序上学习到一致的概率分布。证明了对于任何良好定义的概率分布，序列困惑度在任何因子化下都是不变的。然而，实验证明存在系统偏差，尤其是在任意排列的情况下。  
    **论文亮点**：建立了严格的理论基础来研究LLM的学习机制；发现了位置偏见和局部性偏见影响了LLM的概率分布一致性，为理解和检测LLM不可信的情况提供了新途径。

12. **标题**：NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context  
    **摘要**：首次提出了一个用于评估护理价值观一致性的基准，涵盖了五个核心价值维度。收集了1,100个实际护理行为实例，并通过对话格式增加了对抗性复杂度。  
    **论文亮点**：揭示了Justice是最难评价的价值维度；发现DeepSeek-V3在简单级别数据集中表现最好，而Claude 3.5 Sonnet在高级别数据集中表现最佳；情境学习显著提高了价值一致性。

13. **标题**：Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pathology Foundation Models  
    **摘要**：探讨了结合检索增强生成（RAG）优化的LLMs和病理学基础模型在甲状腺细胞学诊断中的应用。通过动态检索相关案例和诊断标准，提升了LLMs的情境理解力。  
    **论文亮点**：融合了RAG与病理学特定LLMs，显著提高了诊断效率和解释性；基础模型UNI在预测手术病理诊断方面取得了良好的效果。

14. **标题**：Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?  
    **摘要**：评估了13个开源LVLM作为图表理解能力评判者的潜力。设计了成对和点对点的任务，涵盖事实正确性、信息量和相关性等标准。  
    **论文亮点**：一些开源LVLM达到了与GPT-4相近的评判水平；指出了存在的一些偏见，如位置偏好和长度偏见，但仍可作为成本效益较高的自动评估者。

15. **标题**：IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation  
    **摘要**：介绍了一个迭代关键词生成框架IterKey，旨在通过稀疏检索增强RAG。IterKey包含三个阶段：生成关键词、基于检索文档生成答案、验证答案。如果验证失败，则重复过程直到成功。  
    **论文亮点**：在四个QA任务中实现了5%-20%的精度提升；平衡了准确性和可解释性，性能接近密集检索方法。

16. **标题**：A document processing pipeline for the construction of a dataset for topic modeling based on the judgments of the Italian Supreme Court  
    **摘要**：开发了一个文档处理管道，用于创建一个匿名化数据集，以优化意大利最高法院判决的主题建模。该管道整合了文档布局分析、光学字符识别和文本匿名化。  
    **论文亮点**：相比仅使用OCR的方法，该数据集在主题多样性得分和连贯性得分上有明显提高；使用BERTopic提取主题，并用LLMs生成标签和摘要，Claude Sonnet 3.7在标签生成和摘要生成上表现出色。

17. **标题**：Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow  
    **摘要**：评估了黑盒提示优化方法在大规模LLMs（如DeepSeek V3和Gemini 2.0 Flash）上的有效性。结果表明，随着模型规模的增加，这些方法的效果逐渐减弱。  
    **论文亮点**：观察到了逆规模定律，即黑盒优化方法的有效性随着模型大小的增加而下降；为未来研究提供了有价值的见解。

18. **标题**：Large Language Models for Computer-Aided Design: A Survey  
    **摘要**：综述了LLMs在计算机辅助设计（CAD）领域的应用现状和发展前景。概述了CAD的重要性及LLMs的基础知识，并详细描述了LLMs在CAD中的六个关键应用领域。  
    **论文亮点**：首次系统性地探讨了LLMs与CAD的交叉点；提出了未来的研究方向，为该领域的创新提供了广阔的机会。

19. **标题**：OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning  
    **摘要**：提出了OpenThinkIMG，一个开源的端到端框架，用于训练LVLMs学会像人类一样灵活地利用交互式视觉认知解决问题。  
    **论文亮点**：通过引入标准化的视觉工具接口和支持大规模轨迹生成，促进了动态工具调用策略的学习；实验表明，RL训练的代理显著优于静态演示监督微调初始化的代理和其他基线方法。

20. **标题**：Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection  
    **摘要**：提出了一种新颖的轨迹感知自适应令牌选择器（TATS），它可以在视频中选择运动中心的令牌，并与掩码自动编码器（MAE）框架集成进行联合优化。  
    **论文亮点**：允许更激进的掩蔽策略而不影响下游任务性能；在四个基准测试中展示了优越的效果，包括动作识别任务。